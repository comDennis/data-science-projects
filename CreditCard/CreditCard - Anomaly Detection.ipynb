{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import sklearn\n",
    "%matplotlib inline\n",
    "\n",
    "# data loading\n",
    "credit_df = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection\n",
    "Short inspection of the dataset to get a general understanding before going on with the ML-stuff.\n",
    "Let's have a general look at the data first.\n",
    "\n",
    "As we can see, we have 284.807 samples in total, with 492 of these samples being fraudulent transactions (which accounts for 0.173% of the whole dataset). There is a great inequality in the distribution of the two categories, which is typical in such cases (at least it should be, otherwise the credit card company would have some big trouble).\n",
    "\n",
    "The dataset contains 31 features. Unfortunately, most features are not very descriptive since they have been preprocessed with PCA, probably for privacy reasons. Let's have a look at the remaining features in the next cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of samples: \" + str(len(credit_df)) + \"\\n\")\n",
    "print(credit_df.groupby('Class')['Class'].describe())\n",
    "print(\"\\nShare of fraudulent messages: \" + str(len(credit_df[credit_df['Class'] == 1]) / len(credit_df) * 100) + \"%\\n\")\n",
    "print(credit_df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amount\n",
    "Let's have a look at the amounts of the different transactions.\n",
    "As we can see from the stats below, fraudulent activities tend to have a higher amount in general. At the same time, the maximum amount for fraudulent transactions was way lower than the one for normal activities. Funny: Some fraudulent activities with an amount of 0 were recorded, seemes like there are some nice swindlers out there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# normal\n",
    "normal_df = credit_df[credit_df['Class'] == 0]\n",
    "axes[0].set(title = \"Normal\")\n",
    "axes[0].set_ylim([0,120000])\n",
    "axes[0].set_xlim([0,5000])\n",
    "normal_df.head(100000).Amount.hist(color='b', ax = axes[0])\n",
    "\n",
    "# fraud\n",
    "fraud_df = credit_df[credit_df['Class'] == 1]\n",
    "axes[1].set(title = \"Fraud\")\n",
    "axes[1].set_ylim([0,500])\n",
    "axes[1].set_xlim([0,5000])\n",
    "fraud_df.head(100000).Amount.hist(color='r', ax = axes[1])\n",
    "\n",
    "print(credit_df.groupby('Class')['Amount'].describe())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Before handing the data to our model, the data has to be prepared.\n",
    "\n",
    "### Remove redundant features\n",
    "I will not use the time column, since it does not seem to be valuable to me. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df.drop('Time', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale remaining features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "credit_df['Amount'] = StandardScaler().fit_transform(credit_df['Amount'].values.reshape(-1,1))\n",
    "print(credit_df['Amount'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare datasets\n",
    "For the training of the autoencoder, our training set needs to be free from any anomalies, since the model has to learn the representation of normal transactions only.\n",
    "Therefore, the fraudulent transactions will be removed before splitting the dataset into a training and a test set with a relation of 70:30. After that, the fraudulent data will be added to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fraudulent_df = credit_df[credit_df['Class'] == 1]\n",
    "normal_df = credit_df[credit_df['Class'] == 0]\n",
    "\n",
    "X_train, X_test = train_test_split(normal_df, test_size=0.3)\n",
    "X_train.drop('Class', axis=1, inplace=True)\n",
    "X_test = pd.concat([X_test, fraudulent_df])\n",
    "y_true = X_test['Class']\n",
    "X_test.drop('Class', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# define parameters\n",
    "num_encoder_neurons = [20, 10]\n",
    "num_decoder_neurons = [10, 20]\n",
    "\n",
    "activation = 'relu'\n",
    "\n",
    "# build layers\n",
    "input_layer = Input(shape=(X_train.shape[1], ))\n",
    "encoder = Dense(num_encoder_neurons[0], activation=activation)(input_layer)\n",
    "encoder = Dense(num_encoder_neurons[1], activation=activation)(encoder)\n",
    "\n",
    "decoder = Dense(num_decoder_neurons[0], activation=activation)(encoder)\n",
    "decoder = Dense(num_decoder_neurons[1], activation=activation)(encoder)\n",
    "decoder = Dense(X_train.shape[1], activation='relu')(decoder)\n",
    "\n",
    "# build model\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(X_train, X_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=32,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_test, X_test),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "In the next section, we will find the threshold for classifying a transaction as fraudulent and evaluate the performance of the model.\n",
    "\n",
    "Classical measures like the accuracy are not applicable here due to the small share of fraudulent data. Instead, the f1-score, which considers the precision and the recall of a model, will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = autoencoder.predict(X_test)\n",
    "mean_squared_error = np.mean(np.power(X_test - predictions, 2), axis=1)\n",
    "results = pd.DataFrame({'mean_squared_error':mean_squared_error, 'y_true': y_true})\n",
    "print(results['mean_squared_error'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "thresholds = np.arange(0, 100, 0.5)\n",
    "f1_scores = list()\n",
    "y_t = (y_true == 1).values\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred = mean_squared_error > t\n",
    "    f1_scores += [f1_score(y_t, y_pred)]\n",
    "\n",
    "plt.figure(figsize=(12,5)) \n",
    "plt.plot(thresholds, f1_scores)\n",
    "f1_scores = np.array(f1_scores)\n",
    "max_index = np.where(f1_scores == f1_scores.max())[0][0]\n",
    "best_threshold = thresholds[max_index]\n",
    "plt.scatter([best_threshold],[f1_scores.max()], color='r')\n",
    "plt.title(\"F1-Score for multiple thresholds\")\n",
    "plt.ylabel('F1-Score')\n",
    "plt.xlabel('Threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
